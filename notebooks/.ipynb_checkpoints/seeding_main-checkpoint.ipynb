{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "lightweight-picnic",
   "metadata": {},
   "source": [
    "## Main Evaluation: Seeding Strategies in Search-Based Unit Test Generation for Python\n",
    "\n",
    "Provides the empirical evaluation for the Bachelorthesis of Lukas Steffens: Seeding Strategies in Search-Based Unit Test Generation for Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dutch-dubai",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do all necessary imports here\n",
    "import itertools as it\n",
    "import statistics\n",
    "\n",
    "from bisect import bisect_left\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Optional, Dict\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pylatex\n",
    "import scipy.stats as ss\n",
    "import seaborn as sns\n",
    "import glob\n",
    "\n",
    "from pandas import Categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rural-designation",
   "metadata": {},
   "source": [
    "### Useful Functions for Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "canadian-polyester",
   "metadata": {},
   "source": [
    "Implement the Vargha and Delaney (Â12) effect size statistics,\n",
    "taken from a [GitHub Gist](https://gist.github.com/jacksonpradolima/f9b19d65b7f16603c837024d5f8c8a65)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "apart-harmony",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vd_a(treatment: List[float], control: List[float]) -> Tuple[float, str]:\n",
    "    \"\"\"Compute Vargha and Delaney A index\n",
    "\n",
    "    A. Vargha and H. D. Delaney.  A critique and improvement of the CL common language\n",
    "    effect size statistics of McGraw and Wong.  Journal of Educational and Behavioral\n",
    "    Statistics, 25(2):101-132, 2000.\n",
    "\n",
    "    The formula to compute A has been transformed to minimise accuracy errors, see\n",
    "    https://mtorchiano.wordpress.com/2014/05/19/effect-size-of-r-precision/\n",
    "\n",
    "    :param treatment: a list of numbers\n",
    "    :param control: a list of numbers\n",
    "    :return: the value estimate and the magnitude\n",
    "    \"\"\"\n",
    "    m = len(treatment)\n",
    "    n = len(control)\n",
    "\n",
    "    #if m != n:\n",
    "    #    raise ValueError(\"Parameter lists must have equal lengths\")\n",
    "\n",
    "    r = ss.rankdata(treatment + control)\n",
    "    r1 = sum(r[0:m])\n",
    "\n",
    "    # Compute the measure\n",
    "    # A = (r1/m - (m+1)/2)/n  # formula (14) in Vargha and Delaney, 2000\n",
    "    A = (2 * r1 - m * (m + 1)) / (2 * n * m)  # equivalent formula with better accuracy\n",
    "\n",
    "    levels = [0.147, 0.33, 0.474]\n",
    "    magnitudes = [\"negligible\", \"small\", \"medium\", \"large\"]\n",
    "    scaled_A = (A - 0.5) * 2\n",
    "\n",
    "    magnitude = magnitudes[bisect_left(levels, abs(scaled_A))]\n",
    "    estimate = A\n",
    "\n",
    "    return estimate, magnitude"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "japanese-sweet",
   "metadata": {},
   "source": [
    "Implement helper functions for calculating the Vargha and Delaney (Â12) effect size statistics and the Mann Whitney U Test for the different scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "authorized-weekend",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_a12(projectname: str, strategy1: str, strategy2: str, cov_values: pd.DataFrame):\n",
    "    treatment_row = cov_values.loc[(cov_values['ConfigurationId'] == strategy1) & (cov_values['Project'] == projectname)]\n",
    "    control_row = cov_values.loc[(cov_values['ConfigurationId'] == strategy2) & (cov_values['Project'] == projectname)]\n",
    "    treatment = treatment_row.iloc[0]['Coverage Values']\n",
    "    control = control_row.iloc[0]['Coverage Values']\n",
    "    return vd_a(treatment, control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "inner-listing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mwu(projectname: str, strategy1: str, strategy2: str, vals: pd.DataFrame):\n",
    "    alpha = 0.05\n",
    "    p_vals = []\n",
    "\n",
    "    for _, row in cov_values_by_module.iterrows():\n",
    "        if row[config] == strategy1 and row[project] == projectname:\n",
    "            l_s2 = vals.loc[(vals[config] == strategy2) & (vals[project] == projectname) & (vals[cut] == row[cut])]\n",
    "            try:\n",
    "                mwu = ss.mannwhitneyu(row['Coverage Values'], l_s2.iloc[0]['Coverage Values'], alternative='two-sided')\n",
    "                p_vals.append(mwu.pvalue)\n",
    "            except ValueError:\n",
    "                p_vals.append(1) # if all values for both strategies are equal\n",
    "                print('All values are equal.')\n",
    "            except IndexError:\n",
    "                print('No suitable other config found') # if for one config the run failed\n",
    "    \n",
    "    count_sig = 0\n",
    "    for val in p_vals:\n",
    "        if val < alpha:\n",
    "            count_sig += 1\n",
    "            \n",
    "    return float(count_sig) / len(p_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "rolled-thinking",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mwu2(projectname: str, strategy1: str, strategy2: str, vals: pd.DataFrame):\n",
    "    alpha = 0.05\n",
    "    a12_vals = []\n",
    "    p_vals = []\n",
    "\n",
    "    for _, row in cov_values_by_module.iterrows():\n",
    "        if row[config] == strategy1 and row[project] == projectname:\n",
    "            l_s2 = vals.loc[(vals[config] == strategy2) & (vals[project] == projectname) & (vals[cut] == row[cut])]\n",
    "            try:\n",
    "                val, val_string = vd_a(row['Coverage Values'], l_s2.iloc[0]['Coverage Values'])\n",
    "                #a12_vals.append(val)\n",
    "                mwu = ss.mannwhitneyu([val], [0.5], alternative='two-sided')\n",
    "                p_vals.append(mwu.pvalue)\n",
    "            except IndexError:\n",
    "                print('No suitable other config found') # if for one config the run failed\n",
    "            except ValueError:\n",
    "                print(\"All values are equal\")\n",
    "                p_vals.append(1) # if all values for both strategies are equal\n",
    "    \n",
    "            \n",
    "   # try:\n",
    "   #     mwu = ss.mannwhitneyu(a12_vals, [0.5 for x in range(0, len(a12_vals))], alternative='greater')\n",
    "   #     p_vals.append(mwu.pvalue)\n",
    "   # except ValueError:\n",
    "   #     print(\"All values are equal\")\n",
    "   #     p_vals.append(1) # if all values for both strategies are equal\n",
    "\n",
    "    count_sig = 0\n",
    "    for val in p_vals:\n",
    "        print(val)\n",
    "        if val < alpha:\n",
    "            count_sig += 1\n",
    "            \n",
    "    return float(count_sig) / len(p_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "revised-sucking",
   "metadata": {},
   "source": [
    "### Load Data From CSV Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "oriented-pickup",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_orig_dir():\n",
    "    os.chdir('/home/l_pc1-l/ba/own_stuff/ba-thesis/evaluation/eval_env/notebooks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "interpreted-mount",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combines all csv files in the current directory and recursively to one csv file.\n",
    "#adjust the below path on your machine\n",
    "os.chdir(\"/home/l_pc1-l/ba/own_stuff/ba-thesis/evaluation/results/main_run/data\")\n",
    "extension = 'csv'\n",
    "all_filenames = [i for i in glob.glob('./**/*.{}'.format(extension), recursive=True)]\n",
    "\n",
    "#combine all files in the list\n",
    "combined_csv = pd.concat([pd.read_csv(f) for f in all_filenames ])\n",
    "#export to csv\n",
    "combined_csv.to_csv( \"../results.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "recorded-western",
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_orig_dir()\n",
    "# The names of the columns we are interested in\n",
    "cut = \"TargetModule\"\n",
    "project_name = \"ProjectName\"\n",
    "config = \"ConfigurationId\"\n",
    "coverage = \"Coverage\"\n",
    "\n",
    "# How often every CUT was executed\n",
    "runs = 30\n",
    "os.getcwd()\n",
    "# Adjust the following paths on your system if you want to rerun this sheet!\n",
    "PAPER_EXPORT_PATH = Path(\"/home/l_pc1-l/ba/own_stuff/ba-thesis/evaluation\")\n",
    "\n",
    "results = pd.read_csv(Path(\"../..\") / \"results\" / \"main_run\" / \"results.csv\")\n",
    "project_information = pd.read_csv(Path(\"../..\") / \"results\" / \"main_run\" / \"projects.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "chinese-conducting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We tested 106 unique classes, each being executed 30 times per configuration\n"
     ]
    }
   ],
   "source": [
    "number_cuts = len(set(results[cut]))\n",
    "print(f\"I tested {number_cuts} unique classes, each being executed {runs} times per configuration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "compressed-xerox",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I used 5 configurations, namely:\n",
      " - All\n",
      " - Baseline\n",
      " - Initial\n",
      " - Static\n",
      " - Static_and_Dynamic\n"
     ]
    }
   ],
   "source": [
    "f_config_names = list(set(results[config]))\n",
    "config_names = [n for n in f_config_names if type(n) is str]\n",
    "config_names.sort()\n",
    "print(\"I used {} configurations, namely:\\n - {}\".format(\n",
    "    len(config_names), \"\\n - \".join(config_names)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "civil-natural",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column containing the project name to the evaluation results.\n",
    "projects = []\n",
    "for _, row in results.iterrows():\n",
    "    projects.append(row[cut].split(\".\")[0])\n",
    "\n",
    "results.insert(1, \"Project\", projects, True)\n",
    "project = \"Project\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subtle-seminar",
   "metadata": {},
   "source": [
    "### Creating different datasets for the different tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hydraulic-worse",
   "metadata": {},
   "source": [
    "The results obtained from the Pynguin runs need to be adapted to my needs. I create different datasets which I use later to create tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "located-poster",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_data = results.groupby([config, project], as_index=False).agg(\n",
    "    {\n",
    "        coverage: \"mean\",\n",
    "    }\n",
    ")\n",
    "\n",
    "cov_values = results.groupby([config, project])[coverage].apply(list).reset_index(name='Coverage Values')\n",
    "cov_values_by_module = results.groupby([config, project, cut])[coverage].apply(list).reset_index(name='Coverage Values')\n",
    "\n",
    "\n",
    "merged = pd.merge(table_data, table_data, on=project)\n",
    "static_baseline = merged.loc[(merged['ConfigurationId_x'] == 'Baseline') & (merged['ConfigurationId_y'] == 'Static')]\n",
    "static_baseline.insert(2, \"# Modules\", [1,6,2,6,9,13,34,6,4,23], True)\n",
    "\n",
    "static_dynamic_baseline = merged.loc[(merged['ConfigurationId_x'] == 'Baseline') & (merged['ConfigurationId_y'] == 'Static_and_Dynamic')]\n",
    "static_dynamic_baseline.insert(2, \"# Modules\", [1,6,2,6,9,13,34,6,4,23], True)\n",
    "\n",
    "initial_baseline = merged.loc[(merged['ConfigurationId_x'] == 'Baseline') & (merged['ConfigurationId_y'] == 'Initial')]\n",
    "initial_baseline.insert(2, \"# Modules\", [1,6,2,6,9,13,34,6,4,23], True)\n",
    "\n",
    "static_dynamic_static = merged.loc[(merged['ConfigurationId_x'] == 'Static') & (merged['ConfigurationId_y'] == 'Static_and_Dynamic')]\n",
    "static_dynamic_static.insert(2, \"# Modules\", [1,6,2,6,9,13,34,6,4,23], True)\n",
    "\n",
    "all_baseline = merged.loc[(merged['ConfigurationId_x'] == 'Baseline') & (merged['ConfigurationId_y'] == 'All')]\n",
    "all_baseline.insert(2, \"# Modules\", [1,6,2,6,9,13,34,6,4,23], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proud-remark",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "postal-vinyl",
   "metadata": {},
   "source": [
    "## Tables for the different strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civil-poker",
   "metadata": {},
   "source": [
    "In the following I create Latex tables to visualize my answers to the research questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "demonstrated-coach",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "1\n",
      "1.0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "All values are equal\n",
      "1\n",
      "1.0\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "1\n",
      "1.0\n",
      "1.0\n",
      "1\n",
      "1.0\n",
      "1\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "1\n",
      "1\n",
      "1.0\n",
      "1\n",
      "1\n",
      "1.0\n",
      "1\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "1\n",
      "1.0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1.0\n",
      "1\n",
      "1\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "No suitable other config found\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "1\n",
      "1\n",
      "1\n",
      "1.0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1.0\n",
      "1\n",
      "1\n",
      "1\n",
      "1.0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1\n",
      "1.0\n",
      "1\n",
      "1\n",
      "1\n",
      "1.0\n",
      "1.0\n",
      "1\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "1\n",
      "1\n",
      "1.0\n",
      "1\n",
      "1.0\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "1\n",
      "1\n",
      "1\n",
      "1.0\n",
      "1\n",
      "1.0\n",
      "1\n",
      "1\n",
      "1.0\n",
      "1.0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1.0\n",
      "1\n",
      "1\n",
      "All values are equal\n",
      "All values are equal\n",
      "1\n",
      "1\n",
      "1.0\n",
      "1.0\n",
      "\\begin{table}[H]%\n",
      "\\centering%\n",
      "\\begin{tabular}{@{}|c|c|c|c|c|c|@{}}%\n",
      "\\toprule%\n",
      "Project&\\# Modules&Baseline&Static&Â\\textsubscript{12}&\\% > 0.5\\\\%\n",
      "\\midrule%\n",
      "apimd&1&0.2623&0.3855&(0.8507728894173603, 'large')&0.0\\\\%\n",
      "async\\_btree&6&0.3021&0.3061&(0.5111236802413273, 'negligible')&0.0\\\\%\n",
      "codetiming&2&0.9207&0.9245&(0.5254237288135594, 'negligible')&0.0\\\\%\n",
      "docstring\\_parser&6&0.5246&0.5590&(0.550108024691358, 'negligible')&0.0\\\\%\n",
      "flutes&9&0.3930&0.3939&(0.5042565139263252, 'negligible')&0.0\\\\%\n",
      "flutils&13&0.4478&0.4724&(0.5168907506249578, 'negligible')&0.0\\\\%\n",
      "mimesis&34&0.8828&0.8798&(0.4933252866496008, 'negligible')&0.0\\\\%\n",
      "pypara&6&0.3870&0.3887&(0.49595945760854676, 'negligible')&0.0\\\\%\n",
      "pytutils&4&0.6029&0.6043&(0.5036042298618133, 'negligible')&0.0\\\\%\n",
      "string\\_utils&23&0.8649&0.8794&(0.5446161515453639, 'negligible')&0.0\\\\%\n",
      "\\midrule\\bottomrule%\n",
      "%\n",
      "\\end{tabular}%\n",
      "\\caption{Table showing the different values for seeding constants and the corresponding achieved coverage.}%\n",
      "\\label{tabconstvalues}%\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "# Table for evaluating the static constant seeding against the baseline\n",
    "table = pylatex.Table(position=\"H\")\n",
    "tabular = pylatex.Tabular('|c|c|c|c|c|c|', booktabs=True)\n",
    "tabular.add_row([\n",
    "    \"Project\",\n",
    "    \"# Modules\",\n",
    "    \"Baseline\",\n",
    "    \"Static\",\n",
    "    pylatex.NoEscape(r\"Â\\textsubscript{12}\"),\n",
    "    \"% > 0.5\"\n",
    "])\n",
    "\n",
    "tabular.add_hline()\n",
    "for _, row in static_baseline.iterrows():\n",
    "    tabular.add_row([\n",
    "        row[project],\n",
    "        row['# Modules'],\n",
    "        \"{:.4f}\".format(row['Coverage_x']),\n",
    "        \"{:.4f}\".format(row['Coverage_y']),\n",
    "        calc_a12(row[project], \"Static\", \"Baseline\", cov_values),\n",
    "        calc_mwu2(row[project], \"Static\", \"Baseline\", cov_values_by_module)\n",
    "    ])\n",
    "\n",
    "tabular.add_hline()\n",
    "table.append(pylatex.NoEscape(r'\\centering'))\n",
    "table.append(tabular)\n",
    "table.add_caption(\"Table showing the different values for seeding \" +\n",
    "                  \"constants and the corresponding achieved coverage.\")\n",
    "label = pylatex.Label(\"tabconstvalues\")\n",
    "table.append(label)\n",
    "\n",
    "#adjust this path if you want to store the table on your machine\n",
    "with open (\"../../../Thesis/chapters/evaluation_tables/base_static_table.tex\", \"w\") as file:\n",
    "    file.write(table.dumps())\n",
    "print(table.dumps())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "satisfied-addition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "1\n",
      "1.0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1.0\n",
      "1.0\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "1\n",
      "1.0\n",
      "1.0\n",
      "1\n",
      "1.0\n",
      "1\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "1\n",
      "1\n",
      "1.0\n",
      "1.0\n",
      "1\n",
      "1\n",
      "1.0\n",
      "1\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "1.0\n",
      "1.0\n",
      "1\n",
      "1\n",
      "1\n",
      "1.0\n",
      "1.0\n",
      "1\n",
      "1\n",
      "1.0\n",
      "1.0\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "No suitable other config found\n",
      "No suitable other config found\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "1\n",
      "1\n",
      "1\n",
      "1.0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1.0\n",
      "1\n",
      "1\n",
      "1\n",
      "1.0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1\n",
      "1.0\n",
      "1\n",
      "1\n",
      "1\n",
      "1.0\n",
      "1.0\n",
      "1\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "1\n",
      "1\n",
      "1.0\n",
      "1\n",
      "1.0\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "All values are equal\n",
      "1\n",
      "1\n",
      "1\n",
      "1.0\n",
      "1\n",
      "1.0\n",
      "1\n",
      "1\n",
      "1.0\n",
      "1.0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1.0\n",
      "1\n",
      "1\n",
      "All values are equal\n",
      "All values are equal\n",
      "1\n",
      "1\n",
      "1.0\n",
      "1.0\n",
      "\\begin{table}[H]%\n",
      "\\centering%\n",
      "\\begin{tabular}{@{}|c|c|c|c|c|c|@{}}%\n",
      "\\toprule%\n",
      "Project&\\# Modules&Baseline&Static + Dynamic&Â\\textsubscript{12}&\\% > 0.5\\\\%\n",
      "\\midrule%\n",
      "apimd&1&0.2623&0.3117&(0.5838287752675386, 'small')&0.0\\\\%\n",
      "async\\_btree&6&0.3021&0.3027&(0.5020718527062241, 'negligible')&0.0\\\\%\n",
      "codetiming&2&0.9207&0.9249&(0.5340395480225989, 'negligible')&0.0\\\\%\n",
      "docstring\\_parser&6&0.5246&0.5576&(0.5430709876543209, 'negligible')&0.0\\\\%\n",
      "flutes&9&0.3930&0.3969&(0.5060085354896675, 'negligible')&0.0\\\\%\n",
      "flutils&13&0.4478&0.4346&(0.4788914998784539, 'negligible')&0.0\\\\%\n",
      "mimesis&34&0.8828&0.8803&(0.4896855551512086, 'negligible')&0.0\\\\%\n",
      "pypara&6&0.3870&0.3885&(0.5072102303645928, 'negligible')&0.0\\\\%\n",
      "pytutils&4&0.6029&0.6054&(0.5035214251813682, 'negligible')&0.0\\\\%\n",
      "string\\_utils&23&0.8649&0.8729&(0.5314075630252101, 'negligible')&0.0\\\\%\n",
      "\\midrule\\bottomrule%\n",
      "%\n",
      "\\end{tabular}%\n",
      "\\caption{Table showing the different values for seeding constants and the corresponding achieved coverage.}%\n",
      "\\label{tabconstvalues}%\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "#table for evaluating static and dynamic constant seeding against Baseline\n",
    "table = pylatex.Table(position=\"H\")\n",
    "tabular = pylatex.Tabular('|c|c|c|c|c|c|', booktabs=True)\n",
    "tabular.add_row([\n",
    "    \"Project\",\n",
    "    \"# Modules\",\n",
    "    \"Baseline\",\n",
    "    \"Static + Dynamic\",\n",
    "    pylatex.NoEscape(r\"Â\\textsubscript{12}\"),\n",
    "    \"% > 0.5\"\n",
    "])\n",
    "\n",
    "tabular.add_hline()\n",
    "for _, row in static_dynamic_baseline.iterrows():\n",
    "    tabular.add_row([\n",
    "        row[project],\n",
    "        row['# Modules'],\n",
    "        \"{:.4f}\".format(row['Coverage_x']),\n",
    "        \"{:.4f}\".format(row['Coverage_y']),\n",
    "        calc_a12(row[project], \"Static_and_Dynamic\", \"Baseline\", cov_values),\n",
    "        calc_mwu2(row[project], \"Static_and_Dynamic\", \"Baseline\", cov_values_by_module)\n",
    "    ])\n",
    "\n",
    "tabular.add_hline()\n",
    "table.append(pylatex.NoEscape(r'\\centering'))\n",
    "table.append(tabular)\n",
    "table.add_caption(\"Table showing the different values for seeding \" +\n",
    "                  \"constants and the corresponding achieved coverage.\")\n",
    "label = pylatex.Label(\"tabconstvalues\")\n",
    "table.append(label)\n",
    "\n",
    "#adjust this path if you want to store the table on your machine\n",
    "with open (\"../../../Thesis/chapters/evaluation_tables/base_static+dynamic_table.tex\", \"w\") as file:\n",
    "    file.write(table.dumps())\n",
    "print(table.dumps())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unnecessary-burton",
   "metadata": {},
   "outputs": [],
   "source": [
    "#table for evaluating static and dynamic constant seeding against static constant seeding\n",
    "table = pylatex.Table(position=\"H\")\n",
    "tabular = pylatex.Tabular('|c|c|c|c|c|c|', booktabs=True)\n",
    "tabular.add_row([\n",
    "    \"Project\",\n",
    "    \"# Modules\",\n",
    "    \"Static\",\n",
    "    \"Static + Dynamic\",\n",
    "    pylatex.NoEscape(r\"Â\\textsubscript{12}\"),\n",
    "    \"% > 0.5\"\n",
    "])\n",
    "\n",
    "tabular.add_hline()\n",
    "for _, row in static_dynamic_static.iterrows():\n",
    "    tabular.add_row([\n",
    "        row[project],\n",
    "        row['# Modules'],\n",
    "        \"{:.4f}\".format(row['Coverage_x']),\n",
    "        \"{:.4f}\".format(row['Coverage_y']),\n",
    "        calc_a12(row[project], \"Static_and_Dynamic\", \"Static\", cov_values),\n",
    "        calc_mwu2(row[project], \"Static_and_Dynamic\", \"Static\", cov_values_by_module)\n",
    "    ])\n",
    "\n",
    "tabular.add_hline()\n",
    "table.append(pylatex.NoEscape(r'\\centering'))\n",
    "table.append(tabular)\n",
    "table.add_caption(\"Table showing the different values for seeding \" +\n",
    "                  \"constants and the corresponding achieved coverage.\")\n",
    "label = pylatex.Label(\"tabconstvalues\")\n",
    "table.append(label)\n",
    "\n",
    "#adjust this path if you want to store the table on your machine\n",
    "with open (\"../../../Thesis/chapters/evaluation_tables/static_static+dynamic_table.tex\", \"w\") as file:\n",
    "    file.write(table.dumps())\n",
    "print(table.dumps())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concerned-corps",
   "metadata": {},
   "outputs": [],
   "source": [
    "#table for evaluating initial population seeding against Baseline\n",
    "table = pylatex.Table(position=\"H\")\n",
    "tabular = pylatex.Tabular('|c|c|c|c|c|c|', booktabs=True)\n",
    "tabular.add_row([\n",
    "    \"Project\",\n",
    "    \"# Modules\",\n",
    "    \"Baseline\",\n",
    "    \"Initial\",\n",
    "    pylatex.NoEscape(r\"Â\\textsubscript{12}\"),\n",
    "    \"% > 0.5\"\n",
    "])\n",
    "\n",
    "tabular.add_hline()\n",
    "for _, row in initial_baseline.iterrows():\n",
    "    tabular.add_row([\n",
    "        row[project],\n",
    "        row['# Modules'],\n",
    "        \"{:.4f}\".format(row['Coverage_x']),\n",
    "        \"{:.4f}\".format(row['Coverage_y']),\n",
    "        calc_a12(row[project], \"Initial\", \"Baseline\", cov_values),\n",
    "        calc_mwu2(row[project], \"Initial\", \"Baseline\", cov_values_by_module)\n",
    "    ])\n",
    "\n",
    "tabular.add_hline()\n",
    "table.append(pylatex.NoEscape(r'\\centering'))\n",
    "table.append(tabular)\n",
    "table.add_caption(\"Table showing the different values for seeding \" +\n",
    "                  \"constants and the corresponding achieved coverage.\")\n",
    "label = pylatex.Label(\"tabconstvalues\")\n",
    "table.append(label)\n",
    "\n",
    "#adjust this path if you want to store the table on your machine\n",
    "with open (\"../../../Thesis/chapters/evaluation_tables/base_initial_table.tex\", \"w\") as file:\n",
    "    file.write(table.dumps())\n",
    "print(table.dumps())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medical-creek",
   "metadata": {},
   "outputs": [],
   "source": [
    "#table for evaluating all seeding strategies combined against Baseline\n",
    "table = pylatex.Table(position=\"H\")\n",
    "tabular = pylatex.Tabular('|c|c|c|c|c|c|', booktabs=True)\n",
    "tabular.add_row([\n",
    "    \"Project\",\n",
    "    \"# Modules\",\n",
    "    \"Baseline\",\n",
    "    \"Static + Dynamic + Initial\",\n",
    "    pylatex.NoEscape(r\"Â\\textsubscript{12}\"),\n",
    "    \"% > 0.5\"\n",
    "])\n",
    "\n",
    "tabular.add_hline()\n",
    "for _, row in all_baseline.iterrows():\n",
    "    tabular.add_row([\n",
    "        row[project],\n",
    "        row['# Modules'],\n",
    "        \"{:.4f}\".format(row['Coverage_x']),\n",
    "        \"{:.4f}\".format(row['Coverage_y']),\n",
    "        calc_a12(row[project], \"All\", \"Baseline\", cov_values),\n",
    "        calc_mwu2(row[project], \"All\", \"Baseline\", cov_values_by_module)\n",
    "    ])\n",
    "\n",
    "tabular.add_hline()\n",
    "table.append(pylatex.NoEscape(r'\\centering'))\n",
    "table.append(tabular)\n",
    "table.add_caption(\"Table showing the different values for seeding \" +\n",
    "                  \"constants and the corresponding achieved coverage.\")\n",
    "label = pylatex.Label(\"tabconstvalues\")\n",
    "table.append(label)\n",
    "\n",
    "#adjust this path if you want to store the table on your machine\n",
    "with open (\"../../../Thesis/chapters/evaluation_tables/base_all_table.tex\", \"w\") as file:\n",
    "    file.write(table.dumps())\n",
    "print(table.dumps())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coral-substitute",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
